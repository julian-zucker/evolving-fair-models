

@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}

@misc{Dua:2019,
author = "Dua, Dheeru and Graff, Casey",
year = "2017",
title = "{UCI} Machine Learning Repository",
url = "http://archive.ics.uci.edu/ml",
institution = "University of California, Irvine, School of Information and Computer Sciences"
}

@techreport{Packer:2018,
title	= {Text Embeddings Contain Bias. Here's Why That Matters.},
author	= {Ben Packer and M. Mitchell and Mario Guajardo-Céspedes and Yoni Halpern},
year	= {2018},
institution	= {Google}
}

@article{Bellamy:2018,
  author    = {Rachel K. E. Bellamy and
               Kuntal Dey and
               Michael Hind and
               Samuel C. Hoffman and
               Stephanie Houde and
               Kalapriya Kannan and
               Pranay Lohia and
               Jacquelyn Martino and
               Sameep Mehta and
               Aleksandra Mojsilovic and
               Seema Nagar and
               Karthikeyan Natesan Ramamurthy and
               John T. Richards and
               Diptikalyan Saha and
               Prasanna Sattigeri and
               Moninder Singh and
               Kush R. Varshney and
               Yunfeng Zhang},
  title     = {{AI} Fairness 360: An Extensible Toolkit for Detecting, Understanding,
               and Mitigating Unwanted Algorithmic Bias},
  journal   = {CoRR},
  volume    = {abs/1810.01943},
  year      = {2018},
  url       = {http://arxiv.org/abs/1810.01943},
  archivePrefix = {arXiv},
  eprint    = {1810.01943},
  timestamp = {Tue, 30 Oct 2018 10:49:09 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1810-01943},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Speicher:2018,
  author    = {Till Speicher and
               Hoda Heidari and
               Nina Grgic{-}Hlaca and
               Krishna P. Gummadi and
               Adish Singla and
               Adrian Weller and
               Muhammad Bilal Zafar},
  title     = {A Unified Approach to Quantifying Algorithmic Unfairness: Measuring
               Individual {\&} Group Unfairness via Inequality Indices},
  journal   = {CoRR},
  volume    = {abs/1807.00787},
  year      = {2018},
  url       = {http://arxiv.org/abs/1807.00787},
  archivePrefix = {arXiv},
  eprint    = {1807.00787},
  timestamp = {Mon, 13 Aug 2018 16:46:25 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1807-00787},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Barocas:2016,
  author = {Barocas, Solon and Selbst, Andrew D.},
  description = {Big Data's Disparate Impact by Solon Barocas, Andrew D. Selbst},
  journal = {California Law Review},
  language = {English},
  location = {https://scholarship.law.berkeley.edu/californialawreview/vol104/iss3/2/},
  timestamp = {2014-12-21T17:02:48.000+0100},
  title = {{Big Data's Disparate Impact}},
  year = 2016
}



@article{Kleinberg:2016,
  author    = {Jon M. Kleinberg and
               Sendhil Mullainathan and
               Manish Raghavan},
  title     = {Inherent Trade-Offs in the Fair Determination of Risk Scores},
  journal   = {CoRR},
  volume    = {abs/1609.05807},
  year      = {2016},
  url       = {http://arxiv.org/abs/1609.05807},
  archivePrefix = {arXiv},
  eprint    = {1609.05807},
  timestamp = {Mon, 13 Aug 2018 16:46:05 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/KleinbergMR16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Friedler:2019,
 author = {Friedler, Sorelle A. and Scheidegger, Carlos and Venkatasubramanian, Suresh and Choudhary, Sonam and Hamilton, Evan P. and Roth, Derek},
 title = {A Comparative Study of Fairness-enhancing Interventions in Machine Learning},
 booktitle = {Proceedings of the Conference on Fairness, Accountability, and Transparency},
 series = {FAT* '19},
 year = {2019},
 isbn = {978-1-4503-6125-5},
 location = {Atlanta, GA, USA},
 pages = {329--338},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/3287560.3287589},
 doi = {10.1145/3287560.3287589},
 acmid = {3287589},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Fairness-aware machine learning, benchmarks},
}

@INPROCEEDINGS{Papagelis:2000,
author={A. {Papagelis} and D. {Kalles}},
booktitle={Proceedings 12th IEEE Internationals Conference on Tools with Artificial Intelligence. ICTAI 2000},
title={GA Tree: genetically evolved decision trees},
year={2000},
volume={},
number={},
pages={203-206},
keywords={genetic algorithms;decision trees;search problems;learning (artificial intelligence);GA Tree;genetically evolved decision trees;genetic algorithms;classification decision tree evolution;system performance;standard discretized concept learning problems;C4 5;OneR;Decision trees;Genetic algorithms;Impurities;Current measurement;Gain measurement;Machine learning algorithms;Machine learning;Measurement standards;Induction generators;Medical diagnostic imaging},
doi={10.1109/TAI.2000.889871},
ISSN={1082-3409},
month={Nov},}

@article{Zhao:2007,
title = "A multi-objective genetic programming approach to developing Pareto optimal decision trees",
journal = "Decision Support Systems",
volume = "43",
number = "3",
pages = "809 - 826",
year = "2007",
note = "Integrated Decision Support",
issn = "0167-9236",
doi = "https://doi.org/10.1016/j.dss.2006.12.011",
url = "http://www.sciencedirect.com/science/article/pii/S016792360600217X",
author = "Huimin Zhao",
keywords = "Data mining, Binary classification, Decision tree, Cost-sensitive classification, Genetic programming, Multi-objective optimization, Pareto optimality",
abstract = "Classification is a frequently encountered data mining problem. Decision tree techniques have been widely used to build classification models as such models closely resemble human reasoning and are easy to understand. Many real-world classification problems are cost-sensitive, meaning that different types of misclassification errors are not equally costly. Since different decision trees may excel under different cost settings, a set of non-dominated decision trees should be developed and presented to the decision maker for consideration, if the costs of different types of misclassification errors are not precisely determined. This paper proposes a multi-objective genetic programming approach to developing such alternative Pareto optimal decision trees. It also allows the decision maker to specify partial preferences on the conflicting objectives, such as false negative vs. false positive, sensitivity vs. specificity, and recall vs. precision, to further reduce the number of alternative solutions. A diabetes prediction problem and a credit card application approval problem are used to illustrate the application of the proposed approach."
}

@book{Eiben:2015,
 author = {Eiben, A. E. and Smith, James E.},
 title = {Introduction to Evolutionary Computing},
 year = {2015},
 isbn = {3662448734, 9783662448731},
 edition = {2nd},
 publisher = {Springer Publishing Company, Incorporated},
 pages="34"
}

@techreport{Zerbinati:2011,
  TITLE = {{Comparison between MGDA and PAES for Multi-Objective Optimization}},
  AUTHOR = {Zerbinati, Adrien and Desideri, Jean-Antoine and Duvigneau, R{\'e}gis},
  URL = {https://hal.inria.fr/inria-00605423},
  TYPE = {Research Report},
  NUMBER = {RR-7667},
  PAGES = {15},
  INSTITUTION = {{INRIA}},
  YEAR = {2011},
  MONTH = Jun,
  KEYWORDS = {performances ; Pareto front ; Pareto optimality ; Optimization ; gradient descent},
  PDF = {https://hal.inria.fr/inria-00605423/file/RR-7667.pdf},
  HAL_ID = {inria-00605423},
  HAL_VERSION = {v1},
}

@article{Desideri:2012,
title = "Multiple-gradient descent algorithm (MGDA) for multiobjective optimization",
journal = "Comptes Rendus Mathematique",
volume = "350",
number = "5",
pages = "313 - 318",
year = "2012",
issn = "1631-073X",
doi = "https://doi.org/10.1016/j.crma.2012.03.014",
url = "http://www.sciencedirect.com/science/article/pii/S1631073X12000738",
author = "Jean-Antoine Désidéri",
abstract = "One considers the context of the concurrent optimization of several criteria Ji(Y) (i=1,…,n), supposed to be smooth functions of the design vector Y∈RN (n⩽N). An original constructive solution is given to the problem of identifying a descent direction common to all criteria when the current design-point Y0 is not Pareto-optimal. This leads us to generalize the classical steepest-descent method to the multiobjective context by utilizing this direction for the descent. The algorithm is then proved to converge to a Pareto-stationary design-point.
Résumé
On se place dans le contexte de lʼoptimisation concourante de plusieurs critères Ji(Y) (i=1,…,n), fonctions régulières du vecteur de conception Y∈RN (n⩽N). On donne une solution constructive originale au problème de lʼidentification dʼune direction de descente commune à tous les critères en un point Y0 non optimal au sens de Pareto. On est conduit à généraliser la méthode classique du gradient au contexte multiobjectif en utilisant cette direction pour la descente. On prouve que lʼalgorithme converge alors vers un point de conception Pareto-stationnaire."
}

@article{Angwin:2016,
  TITLE = {{Machine Bias: There’s software used across the country to predict future criminals. And it’s biased against blacks.}},
  AUTHOR = {Julia Angwin and Jeff Larson and Surya Mattu and Lauren Kirchner},
  URL = {https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing},
  TYPE = {Article},
  INSTITUTION = {{ProPublica}},
  YEAR = {2016},
  MONTH = May
}

@techreport{Larson:2016,
  TITLE = {{How We Analyzed the COMPAS Recidivism Algorithm}},
  AUTHOR = {Jeff Larson and Surya Mattu and Lauren Kirchner and Julia Angwin},
  URL = {https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm},
  TYPE = {Technical Report},
  INSTITUTION = {{ProPublica}},
  YEAR = {2016},
  MONTH = May
}

@article{Binns:2017,
  author    = {Reuben Binns},
  title     = {Fairness in Machine Learning: Lessons from Political Philosophy},
  journal   = {CoRR},
  volume    = {abs/1712.03586},
  year      = {2017},
  url       = {http://arxiv.org/abs/1712.03586},
  archivePrefix = {arXiv},
  eprint    = {1712.03586},
  timestamp = {Mon, 13 Aug 2018 16:47:18 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1712-03586},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Bao:2019,
title = "Integration of unsupervised and supervised machine learning algorithms for credit risk assessment",
journal = "Expert Systems with Applications",
volume = "128",
pages = "301 - 315",
year = "2019",
issn = "0957-4174",
doi = "https://doi.org/10.1016/j.eswa.2019.02.033",
url = "http://www.sciencedirect.com/science/article/pii/S0957417419301472",
author = "Wang Bao and Ning Lianju and Kong Yue",
keywords = "Credit scoring, Ensemble model, Unsupervised machine learning, Supervised machine learning, Kohonen's self-organizing maps (SOM)",
abstract = "For the sake of credit risk assessment, credit scoring has become a critical tool to discriminate “bad” applicants from “good” applicants for financial institutions. Accordingly, a wide range of supervised machine learning algorithms have been successfully applied to credit scoring; however, integration of unsupervised learning with supervised learning in this field has drawn little consideration. In this work, we propose a combination strategy of integrating unsupervised learning with supervised learning for credit risk assessment. The difference between our work and other previous work on unsupervised integration is that we apply unsupervised learning techniques at two different stages: the consensus stage and dataset clustering stage. Comparisons of model performance are performed based on three credit datasets in four groups: individual models, individual models + consensus model, clustering + individual models, clustering + individual models + consensus model. As a result, integration at either the consensus stage or dataset clustering stage is effective on improving the performance of credit scoring models. Moreover, the combination of the two stages achieves the best performance, thereby confirming the superiority of the proposed integration of unsupervised and supervised machine learning algorithms, which boost our confidence that this strategy can be extended to many other credit datasets from financial institutions."
}

@article{Kretowski:2005,
author = {Kretowski, Marek and Grzes, Marek},
year = {2005},
month = {01},
pages = {401-410},
title = {Global learning of decision trees by an evolutionary algorithm},
journal = {Inform Process Security Syst},
doi = {10.1007/0-387-26325-X_36}
}

@article{Abellan:2017,
title = "A comparative study on base classifiers in ensemble methods for credit scoring",
journal = "Expert Systems with Applications",
volume = "73",
pages = "1 - 10",
year = "2017",
issn = "0957-4174",
doi = "https://doi.org/10.1016/j.eswa.2016.12.020",
url = "http://www.sciencedirect.com/science/article/pii/S0957417416306947",
author = "Joaquín Abellán and Javier G. Castellano",
keywords = "Credit scoring, Ensembles of classifiers, Base classifier, Decision trees, Imprecise Dirichlet model, Uncertainty measures",
abstract = "In the last years, the application of artificial intelligence methods on credit risk assessment has meant an improvement over classic methods. Small improvements in the systems about credit scoring and bankruptcy prediction can suppose great profits. Then, any improvement represents a high interest to banks and financial institutions. Recent works show that ensembles of classifiers achieve the better results for this kind of tasks. In this paper, it is extended a previous work about the selection of the best base classifier used in ensembles on credit data sets. It is shown that a very simple base classifier, based on imprecise probabilities and uncertainty measures, attains a better trade-off among some aspects of interest for this type of studies such as accuracy and area under ROC curve (AUC). The AUC measure can be considered as a more appropriate measure in this grounds, where the different type of errors have different costs or consequences. The results shown here present to this simple classifier as an interesting choice to be used as base classifier in ensembles for credit scoring and bankruptcy prediction, proving that not only the individual performance of a classifier is the key point to be selected for an ensemble scheme."
}

@article{Shen:2019,
title = "A novel ensemble classification model based on neural networks and a classifier optimisation technique for imbalanced credit risk evaluation",
journal = "Physica A: Statistical Mechanics and its Applications",
volume = "526",
pages = "121073",
year = "2019",
issn = "0378-4371",
doi = "https://doi.org/10.1016/j.physa.2019.121073",
url = "http://www.sciencedirect.com/science/article/pii/S0378437119306582",
author = "Feng Shen and Xingchao Zhao and Zhiyong Li and Ke Li and Zhiyi Meng",
keywords = "BP neural network, Credit risk evaluation, Ensemble classification model, PSO algorithm, SMOTE",
abstract = "Significant research has been performed on credit risk evaluation, with many machine learning and data mining techniques being employed for financial decision-making. The back propagation (BP) neural network has been a popular choice for credit risk evaluation problems, but many studies have found classifier ensembles to be superior to single classifiers. In this paper, a novel ensemble model based on the synthetic minority over-sampling technique (SMOTE) and a classifier optimisation technique is proposed for personal credit risk evaluation. To mitigate the negative effects of imbalanced datasets on the performance of the credit evaluation model, the SMOTE technique is used to rebalance the target training dataset. The particle swarm optimisation (PSO) algorithm is employed to search for the best-connected weights and deviations in the BP neural networks. Based on the optimised BP neural network classifiers, an ensemble model is developed that combines the AdaBoost approach with the base classifiers. To ensure that the proposed model provides accurate and stable performance, we thoroughly explore and discuss the optimal parameters for the ensemble classification model. Finally, the proposed ensemble model is tested on German and Australian real-world imbalanced datasets. The results demonstrate that this model is more effective at processing credit data problems compared to the other classification models examined in this study."
}

@article{Torralba:2011,
author="Antonio Torralba and Alexei A. Efros",
title="Unbiased Look at Dataset Bias",
journal="Proc. of IEEE Computer Vision and Pattern Recognition, 2011",
ISSN="",
publisher="",
year="2011",
month="",
volume="",
number="",
pages="1521-1528",
URL="https://ci.nii.ac.jp/naid/10030080158/en/",
DOI="",
}

@inbook{Calders:2013,
author = {Calders, Toon and Zliobaite, Indre},
year = {2013},
month = {01},
pages = {43-57},
title = {Why Unbiased Computational Processes Can Lead to Discriminative Decision Procedures},
journal = {Studies in Applied Philosophy, Epistemology and Rational Ethics},
doi = {10.1007/978-3-642-30487-3_3}
}

@article{Suresh:2019,
  author    = {Harini Suresh and
               John V. Guttag},
  title     = {A Framework for Understanding Unintended Consequences of Machine Learning},
  journal   = {CoRR},
  volume    = {abs/1901.10002},
  year      = {2019},
  url       = {http://arxiv.org/abs/1901.10002},
  archivePrefix = {arXiv},
  eprint    = {1901.10002},
  timestamp = {Sat, 02 Feb 2019 16:56:00 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1901-10002},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
